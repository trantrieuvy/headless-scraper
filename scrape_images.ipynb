{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26faf328",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5ad27",
   "metadata": {},
   "source": [
    "#### Initialize headless browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f82134",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52955b63",
   "metadata": {},
   "source": [
    "#### Load the website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef130d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = 'annibalesiconolfi' # Replace with the desired artist name for example: annibalesiconolfi\n",
    "base_url = f'https://{artist_name}.artstation.com' # The base URL of the artist's page for example: https://vy.artstation.com\n",
    "projects_url = f'{base_url}/projects' # The projects page URL of the artist\n",
    "driver.get(projects_url)\n",
    "time.sleep(5)  # Wait for content to render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507feda",
   "metadata": {},
   "source": [
    "#### Extract URLs of the images from their thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5579508",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser') # get the HTML content of the page / turn the page into a BeautifulSoup searchable object\n",
    "project_links = []\n",
    "for a in soup.find_all('a', href=True): # find all anchor tags \n",
    "    href = a['href'] # find the href attribute of the anchor tag / clickable link (thumbnail)\n",
    "    if re.match(r'^/projects/\\w+$', href): # match the href with the regex pattern to find project links (here starts with /projects/ and ends with a combination of letters, digits and underscores)        \n",
    "        full_link = base_url + href\n",
    "        if full_link not in project_links:\n",
    "            project_links.append(full_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc2654",
   "metadata": {},
   "source": [
    "#### Extract source of images from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4561edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_image_urls = []\n",
    "\n",
    "for i, link in enumerate(project_links):\n",
    "    print(f\"[{i+1}/{len(project_links)}] Visiting: {link}\")\n",
    "    driver.get(link)\n",
    "    time.sleep(4)\n",
    "\n",
    "    project_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    imgs = project_soup.find_all('img') # find all image tags in the project page\n",
    "    for img in imgs:\n",
    "        src = img.get('src') # get the source attribute of the image tag\n",
    "        if src not in hd_image_urls:\n",
    "            hd_image_urls.append(src)\n",
    "            \n",
    "driver.quit()\n",
    "\n",
    "# Save the URLs to a text file\n",
    "with open('urls.txt', 'w') as file:\n",
    "    for url in hd_image_urls:\n",
    "        file.write(url + '\\n')\n",
    "\n",
    "print(\"URLs have been saved to 'urls.txt'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5095a19",
   "metadata": {},
   "source": [
    "#### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save images\n",
    "save_dir = \"downloaded_images\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Download each image\n",
    "for i, url in enumerate(hd_image_urls):\n",
    "    try:\n",
    "        # Get image content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        # Create a filename\n",
    "        ext = url.split('.')[-1].split('?')[0]  # get file extension\n",
    "        filename = f\"image_{i + 1}.{ext}\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        # Save the image\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"✅ Saved: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to download {url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
